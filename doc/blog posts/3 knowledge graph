# How do you integrate Omics data into gen AI LLM model?

In previous posts I described our mission - extending genAI models with scientific omics data and our first design choice - work at the level of individual fold changes. 
In this post I will go over the different options for presenting this data to the LLM model, their pros and cons, and the motivation behind our final choice - knowledge graph.


# Common integration options finetune and RAG

There are two methods that are often used to teach an LLM new data, fine-tune and RAG.

When fine-tuning a model, an existing model is retrained using a custom training set that includes knowledge and tasks targetting the specific application.
This can be done for either foundation model like chatgpt or open source model like llama or deepmind. There is no need for a large training set, because the model has already been trained, and we are only tweaking it. The result is a model that has built-in relevant knowledge. 

Retrieval augmented generation (RAG) is a technique the customization is done in the prompt instead of changing the model. The user prompt is automatically augmented.  Relevant data is injected into the prompt accompanied with an instruction to answer based on it. RAG development is often based on a vector database. This database contains relevant text and data. It can be queried based on keywords and/or semantic queries. Each model invocation involves a vector DB search, injection into the prompt, and feeding the revised prompt into the LLM.

Both of these methods have pros and cons.

Finetuning the model makes it highly customized for your use case. The model is intimately familiar with your data. However, if your data is dynamic, you will need to frequently retrain the model and the retraining process is expensive, requiring expertise and computing resources.

RAG is more flexible, supporting data changes by design. It is lightweight and easy to implement. The quality of the results, however is highly dependent on the quality of your data and your ability to identify and select the relevant sections in the database. It requires a larger context window and may run into the model's limits.

# multi-omics data

The main elements in the cell include genomic data, enzymes and proteins, and metabolites. There is extensive research on each of these, which can be found in online databases like UniProt, NCBI, and ChEMBL. These are all interconnected in a complex web of interactions. For example, a given gene will have a protein enzyme associated with it. The protein may be part of one or more metabolic pathways, have cellular location, be involved in biological processes.  Enzymes may catalyze chemical reactions, which involves matabolites as reactants and as products.

All of this data is highly relevant as context for multi-omics analysis.

The multi-omics assays involve all of these elements. RNA sequencing studies the cell adaptation to the envinronment by looking at the genes that are transcribed and translated to proteins.
Proteomics looks into protein enzymes in the cells. Metabolomics looks at concentration of metabolites. DNA resequencing studies genotypes induced by mutations. 

Thus the data we analyze is highly connected in a web of complicated relationships and our integration should reflect this.

# knowledge graph

There is a third approach to integration - instead of changing the model or the prompt, we can give the model a tool, for example web search, to use in aquiring relevant information for the analysis. What if we could create a tool that can answer targeted queries related based on published data. That will give an LLM agent the power to query for relevant information in its analysis.

Since our data is highly connected in complex ways, an intruiging approach is to use a graph to represent it. Luckily, this technology exists and is gaining momentum. This is the knowledge graph. A knowledge graph is an organized representation of real-world data. Organized in a way that makes semantic interpretation explicit. 

Take for example the following cypher queries (cypher is a language used to query knowledge graphs):

 (Nutrient starvation)-[affects_expression_of {expression_direction: 'up'}]->(gene)

 (protein)-[protein_involved_in_biological_process]->(??)



More complex queries that are easy to use include: what are the genes in this pathway? how does the expression of this gene change under the specified treatment or in general?, and even complex queries like: are there genes related to stress that are upregulated in coculture, but not under starvation?


# knowledge graph as tool

Each knowledge graph (KG) has a well defined schema, which an LLM agent can easily use to form queries.

There are several integration options. We elected to use a subagent. This LLM agent will recieve a text prompt, translate it to one or more cypher queries, and return the result formatted as an LLM friendly text.

This pattern has several benefits. The subagent has its own context, keeping the details of graph queries (which may be large) out of the context of the main agent.
The subagnent prompt can include targetted instructions and example of useful cypher queries based on our specific knowledge graph schema. 

In this modular approach, the graph queries are in a self-contained module that can be evaluated and improved separately.

Graph RAG is another option, creating a query based on the prompt and injecting the results into the augmented prompt. It is less flexible as a single prompt may necessitate multiple graph queries.

Our stack includes 
- biolink - an ontology for biology related knowledge graph
- biocypher - a framework for building biomedical knowledge graphs
- pypath - Python module for processing molecular biology data resources
- neo4j - an online graph database and analytics, used to host and query the graph
- langchain/langgraph - LLM framework

In the next post we will go into the first steps of building a knowledge graph with python code examples.




